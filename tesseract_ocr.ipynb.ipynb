{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyOgVKXCsIz7I2ugbuaCesJh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Tesseract OCR System Work Book"],"metadata":{"id":"FwXq_BaUG4ga"}},{"cell_type":"markdown","source":["### Env Init"],"metadata":{"id":"9IHx4-opKxph"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"811KRQLfz31Q","executionInfo":{"status":"ok","timestamp":1704284799525,"user_tz":-660,"elapsed":20282,"user":{"displayName":"Yuchen Li","userId":"14923965350100155980"}},"outputId":"96841a00-0b99-4902-9ff2-93e74816a433"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","source":["!apt-get install tesseract-ocr\n","!pip install pytesseract\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2WwU8IB50JH0","executionInfo":{"status":"ok","timestamp":1704284814924,"user_tz":-660,"elapsed":15404,"user":{"displayName":"Yuchen Li","userId":"14923965350100155980"}},"outputId":"2df4c27f-2cea-4ba8-96bb-f884c13f1e04"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","The following additional packages will be installed:\n","  tesseract-ocr-eng tesseract-ocr-osd\n","The following NEW packages will be installed:\n","  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n","0 upgraded, 3 newly installed, 0 to remove and 24 not upgraded.\n","Need to get 4,816 kB of archives.\n","After this operation, 15.6 MB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-eng all 1:4.00~git30-7274cfa-1.1 [1,591 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-osd all 1:4.00~git30-7274cfa-1.1 [2,990 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr amd64 4.1.1-2.1build1 [236 kB]\n","Fetched 4,816 kB in 1s (4,252 kB/s)\n","Selecting previously unselected package tesseract-ocr-eng.\n","(Reading database ... 121654 files and directories currently installed.)\n","Preparing to unpack .../tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n","Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n","Selecting previously unselected package tesseract-ocr-osd.\n","Preparing to unpack .../tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n","Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n","Selecting previously unselected package tesseract-ocr.\n","Preparing to unpack .../tesseract-ocr_4.1.1-2.1build1_amd64.deb ...\n","Unpacking tesseract-ocr (4.1.1-2.1build1) ...\n","Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n","Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n","Setting up tesseract-ocr (4.1.1-2.1build1) ...\n","Processing triggers for man-db (2.10.2-1) ...\n","Collecting pytesseract\n","  Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n","Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (23.2)\n","Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (9.4.0)\n","Installing collected packages: pytesseract\n","Successfully installed pytesseract-0.3.10\n"]}]},{"cell_type":"code","source":["import cv2\n","import pytesseract\n","import os\n","import glob\n","from datasets import load_metric"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":350},"id":"E_JsV--gK3BG","executionInfo":{"status":"error","timestamp":1704284816044,"user_tz":-660,"elapsed":1126,"user":{"displayName":"Yuchen Li","userId":"14923965350100155980"}},"outputId":"68a3c7c9-c03b-4502-edef-b507f397b29a"},"execution_count":3,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-c60d5ddb6865>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_metric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'datasets'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"markdown","source":["### Conduct OCR on Test Sets"],"metadata":{"id":"gMsxKLz1K2Zb"}},{"cell_type":"markdown","source":["#### On IAM Dataset"],"metadata":{"id":"MLTNgowpK-KH"}},{"cell_type":"code","source":["# Path to the Tesseract executable\n","# pytesseract.pytesseract.tesseract_cmd = '/path/to/tesseract'  # Uncomment if Tesseract is not in PATH\n","\n","# Directory containing the image files\n","image_directory = \"/content/drive/My Drive/ocr_project/datasets/IAM_data/test/test_image\"\n","\n","# Directory to save the results\n","output_directory = \"/content/drive/My Drive/ocr_project/datasets/IAM_data/test/tesseract_test_output\"\n","os.makedirs(output_directory, exist_ok=True)\n","\n","# Directory to save the images with detected text boxes\n","detected_image_directory = \"/content/drive/My Drive/ocr_project/datasets/IAM_data/test/tesseract_detected_test_images\"\n","os.makedirs(detected_image_directory, exist_ok=True)\n","\n","# Get list of all PNG files in the directory\n","image_files = glob.glob(os.path.join(image_directory, \"*.png\"))\n","\n","# Process each image\n","for img_path in image_files:\n","    image = cv2.imread(img_path)\n","    base_name = os.path.basename(img_path).split('.')[0]\n","    detected_image_path = os.path.join(detected_image_directory, f\"{base_name}_detected.png\")\n","\n","    # Use Tesseract to recognize text on the original image\n","    extracted_text = pytesseract.image_to_string(image)\n","\n","    # Optionally, save the image with detected text boxes (for visualization)\n","    # Tesseract does not provide a straightforward way to draw bounding boxes as PaddleOCR does\n","    # cv2.imwrite(detected_image_path, image)\n","\n","    # Extract the base name of the image file for naming the output file\n","    output_txt_path = os.path.join(output_directory, f\"{base_name}_result.txt\")\n","\n","    # Export the extracted text into a txt file\n","    with open(output_txt_path, 'w') as f:\n","        f.write(extracted_text)\n","\n","print(\"OCR processing complete.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wlrvz15Y0lRA","executionInfo":{"status":"ok","timestamp":1704263509793,"user_tz":-660,"elapsed":712314,"user":{"displayName":"Yuchen Li","userId":"14923965350100155980"}},"outputId":"f2c5e44d-4023-4f26-f7bb-b8b6620b4594"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["OCR processing complete.\n"]}]},{"cell_type":"markdown","source":["#### On Funsd Dataset"],"metadata":{"id":"cZSOevwKLDXo"}},{"cell_type":"code","source":["# Path to the Tesseract executable\n","# pytesseract.pytesseract.tesseract_cmd = '/path/to/tesseract'  # Uncomment if Tesseract is not in PATH\n","\n","# Directory containing the image files\n","image_directory = \"/content/drive/My Drive/ocr_project/datasets/IAM_data/test/test_image\"\n","\n","# Directory to save the results\n","output_directory = \"/content/drive/My Drive/ocr_project/datasets/IAM_data/test/tesseract_test_output\"\n","os.makedirs(output_directory, exist_ok=True)\n","\n","# Directory to save the images with detected text boxes\n","detected_image_directory = \"/content/drive/My Drive/ocr_project/datasets/IAM_data/test/tesseract_detected_test_images\"\n","os.makedirs(detected_image_directory, exist_ok=True)\n","\n","# Get list of all PNG files in the directory\n","image_files = glob.glob(os.path.join(image_directory, \"*.png\"))\n","\n","# Process each image\n","for img_path in image_files:\n","    image = cv2.imread(img_path)\n","    base_name = os.path.basename(img_path).split('.')[0]\n","    detected_image_path = os.path.join(detected_image_directory, f\"{base_name}_detected.png\")\n","\n","    # Use Tesseract to recognize text on the original image\n","    extracted_text = pytesseract.image_to_string(image)\n","\n","    # Optionally, save the image with detected text boxes (for visualization)\n","    # Tesseract does not provide a straightforward way to draw bounding boxes as PaddleOCR does\n","    # cv2.imwrite(detected_image_path, image)\n","\n","    # Extract the base name of the image file for naming the output file\n","    output_txt_path = os.path.join(output_directory, f\"{base_name}_result.txt\")\n","\n","    # Export the extracted text into a txt file\n","    with open(output_txt_path, 'w') as f:\n","        f.write(extracted_text)\n","\n","print(\"OCR processing complete.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"keVFUYMz1m0v","executionInfo":{"status":"ok","timestamp":1704260709506,"user_tz":-660,"elapsed":2049,"user":{"displayName":"Yuchen Li","userId":"14923965350100155980"}},"outputId":"d1d92ea5-4531-4fcc-b0d0-d280a76320e2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" \n","\n"," \n","\n"," \n","\n"," \n","\n"," \n","\n"," \n","\n","MICHELLE LEPRE\n","VM. LOSITO ;\n","co: S.A. RAPISARLDI\n","FS ras MoGLYND -\n","K.P. AUGUSTYN\n","~ BRAND(S) APPLICABLE TRUE\n","~ MEDIA TYPE SALES FORCE APPLIED ~ IRC\n","= MEDIA NAME\n","~ ISSUE FREQUENCY/YEAR\n","~ SPACEICOLOR\n","\n","COUPON ISSUE DATE\n","\n","COUPON EXPIRATION DATE\n","\n","CIRCULATION\n","\n","~ GEOGRAPHICAL AREA(S)\n","\n","COUPON VALUE\n","\n","PACK ANDIOR CARTON\n","\n"," \n","\n","~ TADVERTISING CREATIVE TITLE\n","\n","‘SIGNATURE OF INITIATOR\n","\n","~ DATE INTTIATED\n","IALYTICAL REQUIREMENTS:\n","LIRUE CORE AREAS\n","FoTALNEWYORK TOTAL NEWJERSEY\n","Newhaven Pnowoence\n","TOTALBOSTON ——CAMOEN\n","uarono cconcoro\n","ToTALsANFRMCIECO ePANGMELD\n","srmcuse exTMone\n","rooesren PoRTuwo, ME\n","TOTALPMLADELPHIA TOTALOETAOIT\n","TOTALCHICAGO TOTAL WASHINGTONDC\n","surraco ‘nuunarow\n","\n"," \n","\n"," \n","\n"," \n","\n"," \n","\n"," \n","\n"," \n","\n"," \n","\n"," \n","\n","JANUARY 8, 1992,\n","\n"," \n","\n"," \n","\n"," \n","\n"," \n","\n","REGION 15(X SAN BERMADINO)\n","\n","catoeees\n","\f\n"]}]},{"cell_type":"markdown","source":["### Measurement"],"metadata":{"id":"1879kxxRSS09"}},{"cell_type":"code","source":["# Load the metrics\n","cer_metric = load_metric('cer')\n","wer_metric = load_metric('wer')\n","\n","# Paths to your directories\n","predictionp_printed_dir = \"/content/drive/My Drive/ocr_project/datasets/IAM_data/test/printed_output\"\n","predictionp_writing_dir = \"/content/drive/My Drive/ocr_project/datasets/IAM_data/test/writing_output\"\n","reference_dir = \"/content/drive/My Drive/ocr_project/datasets/IAM_data/test/printed_label\"\n","\n","# Initialize lists for predictions and references\n","prediction_printed_texts = []\n","prediction_writing_texts = []\n","reference_texts = []\n","\n","# Iterate over files in the predictions directory\n","for prediction_file in os.listdir(predictionp_printed_dir):\n","    if prediction_file.endswith('_printed_output.txt'):\n","        # Construct file paths\n","        prediction_path = os.path.join(predictionp_printed_dir, prediction_file)\n","        base_name = prediction_file.replace('_printed_output.txt', '')\n","        reference_file = base_name + '_printed_label.txt'\n","        reference_path = os.path.join(reference_dir, reference_file)\n","\n","        # Read prediction and reference texts\n","        with open(prediction_path, 'r') as file:\n","            prediction_printed_texts.append(file.read().strip())\n","\n","        with open(reference_path, 'r') as file:\n","            reference_texts.append(file.read().strip())\n","\n","for prediction_file in os.listdir(predictionp_writing_dir):\n","    if prediction_file.endswith('_writing_output.txt'):\n","        # Construct file paths\n","        prediction_path = os.path.join(predictionp_writing_dir, prediction_file)\n","        base_name = prediction_file.replace('_writing_output.txt', '')\n","        reference_file = base_name + '_printed_label.txt'\n","        reference_path = os.path.join(reference_dir, reference_file)\n","\n","        # Read prediction and reference texts\n","        with open(prediction_path, 'r') as file:\n","            prediction_writing_texts.append(file.read().strip())\n","\n","        with open(reference_path, 'r') as file:\n","            reference_texts.append(file.read().strip())\n","\n","# Calculate CER and WER for each prediction-reference pair\n","printed_cer_scores = [cer_metric.compute(predictions=[pred], references=[ref]) for pred, ref in zip(prediction_printed_texts, reference_texts)]\n","printed_wer_scores = [wer_metric.compute(predictions=[pred], references=[ref]) for pred, ref in zip(prediction_printed_texts, reference_texts)]\n","writing_cer_scores = [cer_metric.compute(predictions=[pred], references=[ref]) for pred, ref in zip(prediction_writing_texts, reference_texts)]\n","writing_wer_scores = [wer_metric.compute(predictions=[pred], references=[ref]) for pred, ref in zip(prediction_writing_texts, reference_texts)]\n","\n","# Calculate the average scores\n","avg_cer_p = sum(printed_cer_scores) / len(printed_cer_scores)\n","avg_wer_p= sum(printed_wer_scores) / len(printed_wer_scores)\n","avg_cer_w= sum(writing_cer_scores) / len(writing_cer_scores)\n","avg_wer_w= sum(writing_wer_scores) / len(writing_wer_scores)\n","\n","print(f\"Average Character Error Rate (CER) for Printed Texts: {avg_cer_p}\")\n","print(f\"Average Word Error Rate (WER) for Printed Texts:{avg_wer_p}\")\n","print(f\"Average Character Error Rate (CER) for Hand-writing Texts: {avg_cer_w}\")\n","print(f\"Average Word Error Rate (WER) for Hand-writing Texts: {avg_wer_w}\")\n"],"metadata":{"id":"mFru6ecG1mwZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"amh4zDjWFpE7"},"execution_count":null,"outputs":[]}]}